{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f84393-98d8-4928-bfd3-946134db87ec",
   "metadata": {},
   "source": [
    "# Central and Worker "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56693fe6-164d-43d0-becb-a1b0e3762b01",
   "metadata": {},
   "source": [
    "This notebook goes over the necessery code for central and worker federated learning agents, which have their own machine learning pipelines that enable the following incremental actions:\n",
    "1. Global model initilization in central\n",
    "2. Sending initial model to workers\n",
    "3. Training a new model in workers\n",
    "4. Returning model updates to central\n",
    "5. Aggregating updates into a global model\n",
    "6. Repeating steps 2 to 4 until model converges\n",
    "\n",
    "In this project we will use the [Synthetic Financial Datasets For Fraud Detection](https://www.kaggle.com/datasets/ealaxi/paysim1/data) to simulate a fraud detection infrastucture, where the central node is controlled by the trade organization and worker nodes are different banks that belong to that organisation where the trade organisation decides to use federated learning to facilitate a adapting, robust and private fraud detection system for their partners.The import we will use in this notebook are the following:\n",
    "\n",
    "- Pandas\n",
    "- Numpy\n",
    "- Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "792434d7-8475-45a2-805c-0618e8b4ffd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20437/2162656668.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c96556a9-52d2-4f62-be2d-4bd859ee6889",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data_df = pd.read_csv('data/Fraud_Detection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dbd8f72-cc5b-4595-a851-1de6525a070d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.00</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.00</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.00</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362615</th>\n",
       "      <td>743</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>339682.13</td>\n",
       "      <td>C786484425</td>\n",
       "      <td>339682.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C776919290</td>\n",
       "      <td>0.00</td>\n",
       "      <td>339682.13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362616</th>\n",
       "      <td>743</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>6311409.28</td>\n",
       "      <td>C1529008245</td>\n",
       "      <td>6311409.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C1881841831</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362617</th>\n",
       "      <td>743</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>6311409.28</td>\n",
       "      <td>C1162922333</td>\n",
       "      <td>6311409.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C1365125890</td>\n",
       "      <td>68488.84</td>\n",
       "      <td>6379898.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362618</th>\n",
       "      <td>743</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>850002.52</td>\n",
       "      <td>C1685995037</td>\n",
       "      <td>850002.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C2080388513</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362619</th>\n",
       "      <td>743</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>850002.52</td>\n",
       "      <td>C1280323807</td>\n",
       "      <td>850002.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C873221189</td>\n",
       "      <td>6510099.11</td>\n",
       "      <td>7360101.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6362620 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         step      type      amount     nameOrig  oldbalanceOrg  \\\n",
       "0           1   PAYMENT     9839.64  C1231006815      170136.00   \n",
       "1           1   PAYMENT     1864.28  C1666544295       21249.00   \n",
       "2           1  TRANSFER      181.00  C1305486145         181.00   \n",
       "3           1  CASH_OUT      181.00   C840083671         181.00   \n",
       "4           1   PAYMENT    11668.14  C2048537720       41554.00   \n",
       "...       ...       ...         ...          ...            ...   \n",
       "6362615   743  CASH_OUT   339682.13   C786484425      339682.13   \n",
       "6362616   743  TRANSFER  6311409.28  C1529008245     6311409.28   \n",
       "6362617   743  CASH_OUT  6311409.28  C1162922333     6311409.28   \n",
       "6362618   743  TRANSFER   850002.52  C1685995037      850002.52   \n",
       "6362619   743  CASH_OUT   850002.52  C1280323807      850002.52   \n",
       "\n",
       "         newbalanceOrig     nameDest  oldbalanceDest  newbalanceDest  isFraud  \\\n",
       "0             160296.36  M1979787155            0.00            0.00        0   \n",
       "1              19384.72  M2044282225            0.00            0.00        0   \n",
       "2                  0.00   C553264065            0.00            0.00        1   \n",
       "3                  0.00    C38997010        21182.00            0.00        1   \n",
       "4              29885.86  M1230701703            0.00            0.00        0   \n",
       "...                 ...          ...             ...             ...      ...   \n",
       "6362615            0.00   C776919290            0.00       339682.13        1   \n",
       "6362616            0.00  C1881841831            0.00            0.00        1   \n",
       "6362617            0.00  C1365125890        68488.84      6379898.11        1   \n",
       "6362618            0.00  C2080388513            0.00            0.00        1   \n",
       "6362619            0.00   C873221189      6510099.11      7360101.63        1   \n",
       "\n",
       "         isFlaggedFraud  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "...                 ...  \n",
       "6362615               0  \n",
       "6362616               0  \n",
       "6362617               0  \n",
       "6362618               0  \n",
       "6362619               0  \n",
       "\n",
       "[6362620 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d6a03b-08c7-492b-957e-fe5e736b9bdb",
   "metadata": {},
   "source": [
    "## Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1467d6-eb8d-4daa-a2a1-60ee7152fa90",
   "metadata": {},
   "source": [
    "The columns are:\n",
    "- Row index = The amount of logs\n",
    "- Step = One hour in the real world \n",
    "- Type = Transaction type: CASH-IN, CASH-OUT, DEBIT, PAYMENT and TRANSFER\n",
    "- Amount = Unit of local currency\n",
    "- NameOrig = Customer who started the transaction\n",
    "- OldbalanceOrig = Initial balance before the transaction\n",
    "- NewbalanceOrig = New balance after the transaction\n",
    "- NameDest = Customer who is the recipient of the transaction\n",
    "- oldbalanceDest = Initial balance recipient before the transaction.\n",
    "- NewbalanceDest = New balance recipient after the transaction\n",
    "- IsFraud = The transactions made by the fraudulent agents.\n",
    "- IsFlaggedFraud = Existing detection, where more than 200.000 transcations are flagged\n",
    "\n",
    "In order to simulate fraud detection, we need to remove the following columns:\n",
    "- OldbalanceOrg\n",
    "- NewbalanceOrig\n",
    "- OldbalanceDest\n",
    "- NewbalanceDest\n",
    "- IsFlaggedFraud (Should be used for comparison, but not for training a model)\n",
    "\n",
    "After that, we need to modify the following columns:\n",
    "- type = Requires hot one encoding using integers\n",
    "- nameOrig = requires string integer encoding\n",
    "- nameDest = requires string integer encoding\n",
    "- amount = round up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f8ca605-206d-4848-8a70-b33ae875124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting(\n",
    "    source_df: any\n",
    ") -> any:\n",
    "    print('Formatting data')\n",
    "    formated_df = source_df.copy()\n",
    "    \n",
    "    irrelevant_columns = [\n",
    "        'oldbalanceOrg',\n",
    "        'newbalanceOrig',\n",
    "        'oldbalanceDest',\n",
    "        'newbalanceDest'\n",
    "    ]\n",
    "    formated_df.drop(\n",
    "        columns = irrelevant_columns, \n",
    "        inplace = True\n",
    "    )\n",
    "    print('Columns dropped')\n",
    "    formated_df = pd.get_dummies(\n",
    "        data = formated_df, \n",
    "        columns = ['type']\n",
    "    )\n",
    "    \n",
    "    for column in formated_df.columns:\n",
    "        if 'type' in column:\n",
    "            formated_df[column] = formated_df[column].astype(int)\n",
    "    print('One hot coded type')\n",
    "\n",
    "    unique_values_orig = formated_df['nameOrig'].unique()\n",
    "    unique_values_dest = formated_df['nameDest'].unique()\n",
    "    \n",
    "    unique_value_list_orig = unique_values_orig.tolist()\n",
    "    unique_value_list_dest = unique_values_dest.tolist()\n",
    "\n",
    "    print('Orig amount:', len(unique_value_list_orig))\n",
    "    print('Dest amount:', len(unique_value_list_dest))\n",
    "    \n",
    "    set_orig_ids = set(unique_value_list_orig)\n",
    "    set_dest_ids = set(unique_value_list_dest)\n",
    "    intersection = set_dest_ids.intersection(set_orig_ids)\n",
    "\n",
    "    print('Orig and Dest duplicates', len(intersection))\n",
    "    \n",
    "    set_dest_ids.difference_update(intersection)\n",
    "    fixed_unique_value_list_dest = list(set_dest_ids)\n",
    "    print('Fixed Dest amount:',len(fixed_unique_value_list_dest))\n",
    "    \n",
    "    orig_encoding_dict = {}\n",
    "    index = 1\n",
    "    for string in unique_value_list_orig:\n",
    "        if not string in orig_encoding_dict:\n",
    "            orig_encoding_dict[string] = index\n",
    "            index = index + 1\n",
    "\n",
    "    dest_encoding_dict = {}\n",
    "    cont_index = len(orig_encoding_dict) + 1\n",
    "    for string in fixed_unique_value_list_dest:\n",
    "        if not string in dest_encoding_dict:\n",
    "            dest_encoding_dict[string] = cont_index\n",
    "            cont_index = cont_index + 1\n",
    "    print('Orig dict amount:', len(orig_encoding_dict))\n",
    "    print('Dest dict amount:', len(dest_encoding_dict))\n",
    "    \n",
    "    print('Orig and dest string-integer encodings created')\n",
    "\n",
    "    string_orig_values = formated_df['nameOrig'].tolist()\n",
    "    string_dest_values = formated_df['nameDest'].tolist()\n",
    "\n",
    "    orig_encoded_values = []\n",
    "    for string in string_orig_values:\n",
    "        orig_encoded_values.append(orig_encoding_dict[string])\n",
    "\n",
    "    dest_encoded_values = []\n",
    "    for string in string_dest_values:\n",
    "        if not string in dest_encoding_dict:\n",
    "            dest_encoded_values.append(orig_encoding_dict[string])\n",
    "            continue\n",
    "        dest_encoded_values.append(dest_encoding_dict[string])\n",
    "\n",
    "    formated_df['nameOrig'] = orig_encoded_values\n",
    "    formated_df['nameDest'] = dest_encoded_values\n",
    "\n",
    "    print('Orig encoded values amount:', len(orig_encoded_values))\n",
    "    print('Dest encoded values amount:', len(dest_encoded_values))\n",
    "    \n",
    "    print('Orig and dest encodings set')\n",
    "\n",
    "    formated_df['amount'] = formated_df['amount'].round(0).astype(int)\n",
    "    print('Amount rounded')\n",
    "\n",
    "    column_order = [\n",
    "        'step',\n",
    "        'amount',\n",
    "        'nameOrig',\n",
    "        'nameDest',\n",
    "        'type_CASH_IN',\n",
    "        'type_CASH_OUT',\n",
    "        'type_DEBIT',\n",
    "        'type_PAYMENT',\n",
    "        'type_TRANSFER',\n",
    "        'isFraud',\n",
    "        'isFlaggedFraud'\n",
    "    ]\n",
    "    formated_df = formated_df[column_order]\n",
    "    print('Columns reordered')\n",
    "    print('Dataframe shape:', formated_df.shape)\n",
    "    print('Formatting done')\n",
    "    return formated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12445ad2-b554-4bc4-a187-37f67c2e0715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting data\n",
      "Columns dropped\n",
      "One hot coded type\n",
      "Orig amount: 6353307\n",
      "Dest amount: 2722362\n",
      "Orig and Dest duplicates 1769\n",
      "Fixed Dest amount: 2720593\n",
      "Orig dict amount: 6353307\n",
      "Dest dict amount: 2720593\n",
      "Orig and dest string-integer encodings created\n",
      "Orig encoded values amount: 6362620\n",
      "Dest encoded values amount: 6362620\n",
      "Orig and dest encodings set\n",
      "Amount rounded\n",
      "Columns reordered\n",
      "Dataframe shape: (6362620, 11)\n",
      "Formatting done\n"
     ]
    }
   ],
   "source": [
    "formated_data_df = formatting(\n",
    "    source_df = source_data_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ac16fca-ac1d-4ab4-b7dc-156d1972d4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>type_CASH_IN</th>\n",
       "      <th>type_CASH_OUT</th>\n",
       "      <th>type_DEBIT</th>\n",
       "      <th>type_PAYMENT</th>\n",
       "      <th>type_TRANSFER</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9840</td>\n",
       "      <td>1</td>\n",
       "      <td>6788653</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1864</td>\n",
       "      <td>2</td>\n",
       "      <td>6647762</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>3</td>\n",
       "      <td>6405410</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>4</td>\n",
       "      <td>7291669</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>11668</td>\n",
       "      <td>5</td>\n",
       "      <td>8220099</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362615</th>\n",
       "      <td>743</td>\n",
       "      <td>339682</td>\n",
       "      <td>6353303</td>\n",
       "      <td>8111677</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362616</th>\n",
       "      <td>743</td>\n",
       "      <td>6311409</td>\n",
       "      <td>6353304</td>\n",
       "      <td>8024143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362617</th>\n",
       "      <td>743</td>\n",
       "      <td>6311409</td>\n",
       "      <td>6353305</td>\n",
       "      <td>7595045</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362618</th>\n",
       "      <td>743</td>\n",
       "      <td>850003</td>\n",
       "      <td>6353306</td>\n",
       "      <td>7587114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362619</th>\n",
       "      <td>743</td>\n",
       "      <td>850003</td>\n",
       "      <td>6353307</td>\n",
       "      <td>6746168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6362620 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         step   amount  nameOrig  nameDest  type_CASH_IN  type_CASH_OUT  \\\n",
       "0           1     9840         1   6788653             0              0   \n",
       "1           1     1864         2   6647762             0              0   \n",
       "2           1      181         3   6405410             0              0   \n",
       "3           1      181         4   7291669             0              1   \n",
       "4           1    11668         5   8220099             0              0   \n",
       "...       ...      ...       ...       ...           ...            ...   \n",
       "6362615   743   339682   6353303   8111677             0              1   \n",
       "6362616   743  6311409   6353304   8024143             0              0   \n",
       "6362617   743  6311409   6353305   7595045             0              1   \n",
       "6362618   743   850003   6353306   7587114             0              0   \n",
       "6362619   743   850003   6353307   6746168             0              1   \n",
       "\n",
       "         type_DEBIT  type_PAYMENT  type_TRANSFER  isFraud  isFlaggedFraud  \n",
       "0                 0             1              0        0               0  \n",
       "1                 0             1              0        0               0  \n",
       "2                 0             0              1        1               0  \n",
       "3                 0             0              0        1               0  \n",
       "4                 0             1              0        0               0  \n",
       "...             ...           ...            ...      ...             ...  \n",
       "6362615           0             0              0        1               0  \n",
       "6362616           0             0              1        1               0  \n",
       "6362617           0             0              0        1               0  \n",
       "6362618           0             0              1        1               0  \n",
       "6362619           0             0              0        1               0  \n",
       "\n",
       "[6362620 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formated_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fb80c03-27c7-4e22-a13a-09a6e21362a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_data_df.to_csv('data/Formated_Fraud_Detection_Data.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc8a8305-37c6-4b49-9679-99568471033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Formated_Fraud_Detection_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e836ef-3cd0-4063-8478-80683f1d3093",
   "metadata": {},
   "source": [
    "## Regular Learning with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c087b3f4-efeb-4d92-87c6-e73beaa11443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "987054b4-1b62-4d76-8019-77ea927be9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def preprocess_into_tensors(\n",
    "    data_path: str,\n",
    "    used_columns: list,\n",
    "    rows: int,\n",
    "    scaled_columns: list,\n",
    "    target_column: str,\n",
    "    set_seed: int\n",
    ") -> any:\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    preprocessed_df = df[used_columns]\n",
    "\n",
    "    preprocessed_df = preprocessed_df[:rows]\n",
    "\n",
    "    for column in scaled_columns:\n",
    "        mean = preprocessed_df[column].mean()\n",
    "        std_dev = preprocessed_df[column].std()\n",
    "        preprocessed_df[column] = (preprocessed_df[column] - mean)/std_dev\n",
    "\n",
    "    X = preprocessed_df.drop(target_column, axis = 1).values\n",
    "    y = preprocessed_df[target_column].values\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, \n",
    "        y, \n",
    "        test_size = 0.2, \n",
    "        random_state = set_seed\n",
    "    )\n",
    "\n",
    "    print('X train:',X_train.shape)\n",
    "    print('X test:',X_test.shape)\n",
    "    print('Y train:',y_train.shape)\n",
    "    print('Y test:',y_test.shape)\n",
    "\n",
    "    X_train = np.array(X_train, dtype=np.float32)\n",
    "    X_test = np.array(X_test, dtype=np.float32)\n",
    "    y_train = np.array(y_train, dtype=np.int32)\n",
    "    y_test = np.array(y_test, dtype=np.int32)\n",
    "    \n",
    "    train_tensor = TensorDataset(\n",
    "        torch.tensor(X_train), \n",
    "        torch.tensor(y_train, dtype=torch.float32)\n",
    "    )\n",
    "    test_tensor = TensorDataset(\n",
    "        torch.tensor(X_test), \n",
    "        torch.tensor(y_test, dtype=torch.float32)\n",
    "    )\n",
    "\n",
    "    return X_train.shape[1], train_tensor, test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4aa2328-0a47-499f-aded-3d68226049b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, dim, bias=True):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.linear = nn.Linear(dim, 1, bias=bias)\n",
    "        self.loss = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x).view(-1)\n",
    "\n",
    "    @staticmethod\n",
    "    def train_step(model, batch):\n",
    "        x, y = batch\n",
    "        out = model(x)\n",
    "        loss = model.loss(out, y)\n",
    "        return loss\n",
    "\n",
    "    @staticmethod\n",
    "    def test_step(model, batch):\n",
    "        x, y = batch\n",
    "        out = model(x)\n",
    "        loss = model.loss(out, y)\n",
    "        preds = out > 0 # Predict y = 1 if P(y = 1) > 0.5\n",
    "        corrects = torch.tensor(torch.sum(preds == y).item())\n",
    "        return loss, corrects\n",
    "\n",
    "def get_loaders(\n",
    "    set_seed: int,\n",
    "    sample_rate: float,\n",
    "    train_tensor: any,\n",
    "    test_tensor: any\n",
    ") -> any:\n",
    "    train_loader = DataLoader(\n",
    "        train_tensor,\n",
    "        batch_size=int(len(train_tensor) * sample_rate),\n",
    "        generator=torch.Generator().manual_seed(set_seed)\n",
    "    )\n",
    "    test_loader = DataLoader(test_tensor, 64)\n",
    "    return train_loader,test_loader\n",
    "\n",
    "def train(\n",
    "    model: any, \n",
    "    train_loader: any, \n",
    "    opt_func: any, \n",
    "    learning_rate: float, \n",
    "    num_epochs: int,  \n",
    "    random_seed: int, \n",
    "    verbose = True\n",
    ") -> int:\n",
    "    optimizer = opt_func(model.parameters(), learning_rate)\n",
    "    model_type = type(model)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model_type.train_step(model, batch)\n",
    "            loss.backward()\n",
    "            losses.append(loss)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Epoch {}, loss = {}\".format(epoch + 1, torch.sum(loss) / len(train_loader)))\n",
    "    \n",
    "def test(\n",
    "    model: any, \n",
    "    test_loader: any\n",
    ") -> any:\n",
    "    with torch.no_grad():\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        total_size = 0\n",
    "        \n",
    "        for batch in test_loader:\n",
    "            total_size += len(batch[1])\n",
    "            loss, corrects = model.test_step(model, batch)\n",
    "            losses.append(loss)\n",
    "            accuracies.append(corrects)\n",
    "\n",
    "        average_loss = np.array(loss).sum() / total_size\n",
    "        total_accuracy = np.array(accuracies).sum() / total_size\n",
    "        return average_loss, total_accuracy\n",
    "\n",
    "def run_model_pipeline(\n",
    "    set_seed: int,\n",
    "    learning_rate: float,\n",
    "    sample_rate: float,\n",
    "    num_epochs: int,\n",
    "    input_dim: int,\n",
    "    train_tensor: any,\n",
    "    test_tensor: any\n",
    ") -> any:\n",
    "    torch.manual_seed(set_seed)\n",
    "    print('Loaders')\n",
    "    given_train_loader, given_test_loader = get_loaders(\n",
    "        set_seed,\n",
    "        sample_rate,\n",
    "        train_tensor,\n",
    "        test_tensor\n",
    "    )\n",
    "    print('Model')\n",
    "    lr_model = LogisticRegression(dim = input_dim)\n",
    "    print('Train')\n",
    "    train(\n",
    "        model = lr_model, \n",
    "        train_loader = given_train_loader, \n",
    "        opt_func = torch.optim.SGD, \n",
    "        learning_rate = learning_rate, \n",
    "        num_epochs = num_epochs,  \n",
    "        random_seed = set_seed, \n",
    "        verbose = True\n",
    "    )\n",
    "    \n",
    "    print('Test')\n",
    "    average_loss, total_accuracy = test(\n",
    "        model = lr_model, \n",
    "        test_loader = given_test_loader\n",
    "    )\n",
    "    print('Complete')\n",
    "    return average_loss, total_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef994480-f5e7-498b-b657-06ad1b78f809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train: (8000, 6)\n",
      "X test: (2000, 6)\n",
      "Y train: (8000,)\n",
      "Y test: (2000,)\n"
     ]
    }
   ],
   "source": [
    "input_dim, train_tensor, test_tensor = preprocess_into_tensors(\n",
    "    data_path = 'data/Formated_Fraud_Detection_Data.csv',\n",
    "    used_columns = [\n",
    "        'amount',\n",
    "        'type_CASH_IN',\n",
    "        'type_CASH_OUT',\n",
    "        'type_DEBIT',\n",
    "        'type_PAYMENT',\n",
    "        'type_TRANSFER',\n",
    "        'isFraud'\n",
    "    ],\n",
    "    rows = 10000,\n",
    "    scaled_columns = [\n",
    "        'amount'\n",
    "    ],\n",
    "    target_column = 'isFraud',\n",
    "    set_seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54aeac6d-d711-408c-a856-b4b35dfb6b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaders\n",
      "Model\n",
      "Train\n",
      "Epoch 1, loss = 0.005733905825763941\n",
      "Epoch 2, loss = 0.005491575691848993\n",
      "Epoch 3, loss = 0.005264477338641882\n",
      "Epoch 4, loss = 0.005051491782069206\n",
      "Epoch 5, loss = 0.004851583391427994\n",
      "Test\n",
      "Complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00022987823188304901, 0.908)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model_pipeline(\n",
    "    set_seed = 42,\n",
    "    learning_rate = 0.001,\n",
    "    sample_rate = 0.01,\n",
    "    num_epochs = 5,\n",
    "    input_dim = input_dim,\n",
    "    train_tensor = train_tensor,\n",
    "    test_tensor = test_tensor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f9f44e-269c-4ce5-99a4-704d82167408",
   "metadata": {},
   "source": [
    "## Federated Learning with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ea4729c-6c9e-47af-a094-0e0c5b1fb272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6687d53c-443d-4030-9f8c-3492f1cac524",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def preprocess_into_tensors(\n",
    "    data_path: str,\n",
    "    used_columns: list,\n",
    "    rows: int,\n",
    "    scaled_columns: list,\n",
    "    target_column: str,\n",
    "    set_seed: int\n",
    ") -> any:\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    preprocessed_df = df[used_columns]\n",
    "\n",
    "    preprocessed_df = preprocessed_df[:rows]\n",
    "\n",
    "    for column in scaled_columns:\n",
    "        mean = preprocessed_df[column].mean()\n",
    "        std_dev = preprocessed_df[column].std()\n",
    "        preprocessed_df[column] = (preprocessed_df[column] - mean)/std_dev\n",
    "\n",
    "    X = preprocessed_df.drop(target_column, axis = 1).values\n",
    "    y = preprocessed_df[target_column].values\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, \n",
    "        y, \n",
    "        test_size = 0.2, \n",
    "        random_state = set_seed\n",
    "    )\n",
    "\n",
    "    print('X train:',X_train.shape)\n",
    "    print('X test:',X_test.shape)\n",
    "    print('Y train:',y_train.shape)\n",
    "    print('Y test:',y_test.shape)\n",
    "\n",
    "    X_train = np.array(X_train, dtype=np.float32)\n",
    "    X_test = np.array(X_test, dtype=np.float32)\n",
    "    y_train = np.array(y_train, dtype=np.int32)\n",
    "    y_test = np.array(y_test, dtype=np.int32)\n",
    "    \n",
    "    train_tensor = TensorDataset(\n",
    "        torch.tensor(X_train), \n",
    "        torch.tensor(y_train, dtype=torch.float32)\n",
    "    )\n",
    "    test_tensor = TensorDataset(\n",
    "        torch.tensor(X_test), \n",
    "        torch.tensor(y_test, dtype=torch.float32)\n",
    "    )\n",
    "\n",
    "    return X_train.shape[1], train_tensor, test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "395f96d0-5f6d-4820-928d-f70b8c04b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FederatedLogisticRegression(nn.Module):\n",
    "    def __init__(self, dim, bias=True):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.linear = nn.Linear(dim, 1, bias=bias)\n",
    "        self.loss = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x).view(-1)\n",
    "\n",
    "    @staticmethod\n",
    "    def train_step(model, batch):\n",
    "        x, y = batch\n",
    "        out = model(x)\n",
    "        loss = model.loss(out, y)\n",
    "        return loss\n",
    "\n",
    "    @staticmethod\n",
    "    def test_step(model, batch):\n",
    "        x, y = batch\n",
    "        out = model(x)\n",
    "        loss = model.loss(out, y)\n",
    "        preds = out > 0 # Predict y = 1 if P(y = 1) > 0.5\n",
    "        corrects = torch.tensor(torch.sum(preds == y).item())\n",
    "        return loss, corrects\n",
    "\n",
    "    @staticmethod\n",
    "    def get_parameters(model):\n",
    "        return model.state_dict()\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_parameters(model, parameters):\n",
    "        model.load_state_dict(parameters)\n",
    "\n",
    "def get_loaders(\n",
    "    set_seed: int,\n",
    "    sample_rate: float,\n",
    "    train_tensor: any,\n",
    "    test_tensor: any\n",
    ") -> any:\n",
    "    train_loader = DataLoader(\n",
    "        train_tensor,\n",
    "        batch_size=int(len(train_tensor) * sample_rate),\n",
    "        generator=torch.Generator().manual_seed(set_seed)\n",
    "    )\n",
    "    test_loader = DataLoader(test_tensor, 64)\n",
    "    return train_loader,test_loader\n",
    "\n",
    "def train(\n",
    "    model: any, \n",
    "    train_loader: any, \n",
    "    opt_func: any, \n",
    "    learning_rate: float, \n",
    "    num_epochs: int,  \n",
    "    random_seed: int, \n",
    "    verbose = True\n",
    ") -> int:\n",
    "    optimizer = opt_func(model.parameters(), learning_rate)\n",
    "    model_type = type(model)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model_type.train_step(model, batch)\n",
    "            loss.backward()\n",
    "            losses.append(loss)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Epoch {}, loss = {}\".format(epoch + 1, torch.sum(loss) / len(train_loader)))\n",
    "   \n",
    "def test(\n",
    "    model: any, \n",
    "    test_loader: any\n",
    ") -> any:\n",
    "    with torch.no_grad():\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        total_size = 0\n",
    "        \n",
    "        for batch in test_loader:\n",
    "            total_size += len(batch[1])\n",
    "            loss, corrects = model.test_step(model, batch)\n",
    "            losses.append(loss)\n",
    "            accuracies.append(corrects)\n",
    "\n",
    "        average_loss = np.array(loss).sum() / total_size\n",
    "        total_accuracy = np.array(accuracies).sum() / total_size\n",
    "        return average_loss, total_accuracy\n",
    "\n",
    "def federated_model_pipeline(\n",
    "    given_parameters: any,\n",
    "    set_seed: int,\n",
    "    learning_rate: float,\n",
    "    sample_rate: float,\n",
    "    num_epochs: int,\n",
    "    input_dim: int,\n",
    "    train_tensor: any,\n",
    "    test_tensor: any\n",
    ") -> any:\n",
    "    torch.manual_seed(set_seed)\n",
    "    print('Loaders')\n",
    "    given_train_loader, given_test_loader = get_loaders(\n",
    "        set_seed,\n",
    "        sample_rate,\n",
    "        train_tensor,\n",
    "        test_tensor\n",
    "    )\n",
    "    print('Fed Model')\n",
    "    lr_model = FederatedLogisticRegression(dim = input_dim)\n",
    "    if given_parameters: \n",
    "        lr_model.apply_parameters(lr_model,given_parameters)\n",
    "    print('Train')\n",
    "    train(\n",
    "        model = lr_model, \n",
    "        train_loader = given_train_loader, \n",
    "        opt_func = torch.optim.SGD, \n",
    "        learning_rate = learning_rate, \n",
    "        num_epochs = num_epochs,  \n",
    "        random_seed = set_seed, \n",
    "        verbose = True\n",
    "    )\n",
    "    \n",
    "    print('Test')\n",
    "    average_loss, total_accuracy = test(\n",
    "        model = lr_model, \n",
    "        test_loader = given_test_loader\n",
    "    )\n",
    "    print('Complete')\n",
    "    #model_type = type(model)\n",
    "    #parameters = lr_model.get_parameters()\n",
    "    parameters = lr_model.get_parameters(lr_model)\n",
    "    return average_loss, total_accuracy, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3caa1250-807a-412d-9b80-c9e1379b0759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train: (8000, 6)\n",
      "X test: (2000, 6)\n",
      "Y train: (8000,)\n",
      "Y test: (2000,)\n"
     ]
    }
   ],
   "source": [
    "input_dim, train_tensor, test_tensor = preprocess_into_tensors(\n",
    "    data_path = 'data/Formated_Fraud_Detection_Data.csv',\n",
    "    used_columns = [\n",
    "        'amount',\n",
    "        'type_CASH_IN',\n",
    "        'type_CASH_OUT',\n",
    "        'type_DEBIT',\n",
    "        'type_PAYMENT',\n",
    "        'type_TRANSFER',\n",
    "        'isFraud'\n",
    "    ],\n",
    "    rows = 10000,\n",
    "    scaled_columns = [\n",
    "        'amount'\n",
    "    ],\n",
    "    target_column = 'isFraud',\n",
    "    set_seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6779cf29-79c4-4b8e-9ca9-7a7baf2da8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaders\n",
      "Fed Model\n",
      "Train\n",
      "Epoch 1, loss = 0.005733905825763941\n",
      "Epoch 2, loss = 0.005491575691848993\n",
      "Epoch 3, loss = 0.005264477338641882\n",
      "Epoch 4, loss = 0.005051491782069206\n",
      "Epoch 5, loss = 0.004851583391427994\n",
      "Test\n",
      "Complete\n",
      "0.00022987823188304901\n",
      "0.908\n",
      "OrderedDict([('linear.weight', tensor([[ 0.2859,  0.2883, -0.1216,  0.3666, -0.1894,  0.0594]])), ('linear.bias', tensor([-0.4066]))])\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, trained_model_1 = federated_model_pipeline(\n",
    "    given_parameters = None,\n",
    "    set_seed = 42,\n",
    "    learning_rate = 0.001,\n",
    "    sample_rate = 0.01,\n",
    "    num_epochs = 5,\n",
    "    input_dim = input_dim,\n",
    "    train_tensor = train_tensor,\n",
    "    test_tensor = test_tensor\n",
    ")\n",
    "print(loss)\n",
    "print(accuracy)\n",
    "print(trained_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6152a60a-c39f-444e-89dd-f52ace19fd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaders\n",
      "Fed Model\n",
      "Train\n",
      "Epoch 1, loss = 0.004663796629756689\n",
      "Epoch 2, loss = 0.004487242549657822\n",
      "Epoch 3, loss = 0.004321107640862465\n",
      "Epoch 4, loss = 0.004164637066423893\n",
      "Epoch 5, loss = 0.00401713652536273\n",
      "Test\n",
      "Complete\n",
      "0.00018978530168533325\n",
      "0.964\n",
      "OrderedDict([('linear.weight', tensor([[ 0.2598,  0.2437, -0.1441,  0.3591, -0.2726,  0.0390]])), ('linear.bias', tensor([-0.5849]))])\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, trained_model_2 = federated_model_pipeline(\n",
    "    given_parameters = trained_model_1,\n",
    "    set_seed = 42,\n",
    "    learning_rate = 0.001,\n",
    "    sample_rate = 0.01,\n",
    "    num_epochs = 5,\n",
    "    input_dim = input_dim,\n",
    "    train_tensor = train_tensor,\n",
    "    test_tensor = test_tensor\n",
    ")\n",
    "print(loss)\n",
    "print(accuracy)\n",
    "print(trained_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a85e7-cd75-4a53-8739-0e3a63c74ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7ad885c-e3cb-480f-868f-15f7375d9596",
   "metadata": {},
   "source": [
    "## Central ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2dbc7b-88e5-45aa-ad11-8d50b9994a4e",
   "metadata": {},
   "source": [
    "Used imports are:\n",
    "- pip install pandas\n",
    "- pip install numpy\n",
    "- pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ad8761-2a77-4b57-90d3-abaaac553767",
   "metadata": {},
   "source": [
    "## Worker ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e39eaa3-0b0c-43d6-a8ba-b0fb43922af2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
