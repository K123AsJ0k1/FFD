{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to include\n",
    "Create central node, worker nodes update\n",
    "\n",
    "Preprocessing, training, testing, inference, update\n",
    "\n",
    "## Models to implement\n",
    "Random forest, neural network, dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE_PATH = \"~/Documents/Networked AI systems/data/PS_20174392719_1491204439457_log.csv\"\n",
    "#DATA_FILE_PATH = \"~/Documents/Networked AI systems/data/data_subset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data reading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column `nameOrig` contains 6353307 unique values and `nameDest` 2722362, so it is unfeasible to do one-hot encoding for them. It is also possible it would not provide us with any useful information. The most common values in `nameOrig` had only 3 occurrences and in `nameDest` they were around 100.\n",
    "\n",
    "`isFlaggedFraud` seemed a bit confusing so it is also dropped here. The description was \"flags illegal attempts to transfer more than 200.000 in a single transaction\".\n",
    "\n",
    "One-hot encoding is performed on the `type` column since it contains string values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    df = readData()\n",
    "    df = dataPreprocessing(df)\n",
    "    return df\n",
    "\n",
    "def readData(data_file=DATA_FILE_PATH):\n",
    "    return pd.read_csv(data_file)\n",
    "\n",
    "def dataPreprocessing(df):\n",
    "    df.drop(columns=[\"nameOrig\", \"nameDest\", \"isFlaggedFraud\"], inplace=True)\n",
    "    df = pd.get_dummies(df)\n",
    "    df[\"isFraud\"] = df[\"isFraud\"].astype(bool)\n",
    "    return df\n",
    "\n",
    "def dataSplit(df):\n",
    "    x = df[df.columns.drop([\"isFraud\"])]\n",
    "    y = df[\"isFraud\"]\n",
    "    return train_test_split(x, y, test_size=0.25, random_state=2024)\n",
    "\n",
    "def scaleData(data):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the best parameters for the model. The configuration can be found in the file `conf.py`. **Currently not in use.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_random_search = RandomizedSearchCV(\n",
    "#                        estimator=RandomForestRegressor(), \n",
    "#                        param_distributions=conf.rf_search_grid,\n",
    "#                        **conf.rand_search_cv_params\n",
    "#                        )\n",
    "# model_random_search.fit(X_train, y_train)\n",
    "#\n",
    "# model_best = model_random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/utils/validation.py:507: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  array.dtypes.apply(is_sparse).any()):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def createRfModel(X_train, y_train):\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=2024)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def createNnModel(X_train_scaled, y_train):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(100, 50), activation=\"relu\", solver=\"adam\", max_iter=500, random_state=2024)\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score 0.9964976691991664\n",
      "Test accuracy score 0.996200307420528\n"
     ]
    }
   ],
   "source": [
    "def getAccuracy(model, predictors, correct_classes):\n",
    "    predicted_classes = model.predict(predictors).astype(bool)\n",
    "    return accuracy_score(correct_classes, predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main control code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df = getData()\n",
    "    X_train, X_test, y_train, y_test = dataSplit(df)\n",
    "    X_train_scaled = scaleData(X_train)\n",
    "    X_test_scaled = scaleData(X_test)\n",
    "    range_start = 0\n",
    "    data_range = range(range_start, range_start + math.floor(len(X_train) / 5))\n",
    "    rf_model = createRfModel(X_train[data_range], y_train[data_range])\n",
    "    nn_model = createNnModel(X_train_scaled[data_range], y_train[data_range])\n",
    "    print(\"Random forest training accuracy score\", getAccuracy(rf_model, X_train, y_train))\n",
    "    print(\"Random forest test accuracy score\", getAccuracy(rf_model, X_test, y_test))\n",
    "    print(\"Multilayer perceptron training accuracy score\", getAccuracy(nn_model, X_train_scaled, y_train))\n",
    "    print(\"Multilayer perceptron test accuracy score\", getAccuracy(nn_model, X_test_scaled, y_test))\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
